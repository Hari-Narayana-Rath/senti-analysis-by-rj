{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l3d0maEiiw1X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jmPR_SIDjBi_"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('Review.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEFnoLTsqog2"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pU0laLLrUMy"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.head(777)"
      ],
      "metadata": {
        "id": "z50KsnX01sv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7fj787alCUb"
      },
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD4y94psrfLC"
      },
      "outputs": [],
      "source": [
        "example=df['Text'][5]\n",
        "example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8VMH2cdroFH"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "tokens = nltk.word_tokenize(example)\n",
        "tokens[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trRTd0eZrxQ1"
      },
      "outputs": [],
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "tagged[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BtqKODYsR8l"
      },
      "outputs": [],
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "entities = nltk.chunk.ne_chunk(tagged)\n",
        "entities.pprint()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGep-Pt-sbz7"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from tqdm.notebook import tqdm\n",
        "nltk.download('vader_lexicon')\n",
        "pk = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YX9Ec7qVsnDD"
      },
      "outputs": [],
      "source": [
        "pk.polarity_scores('I am so happy!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyeEm2jKsrhh"
      },
      "outputs": [],
      "source": [
        "pk.polarity_scores('This is the worst thing ever.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kzb69W1YstwY"
      },
      "outputs": [],
      "source": [
        "pk.polarity_scores(example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC2JE8Ahu0bK"
      },
      "outputs": [],
      "source": [
        "# Run the polarity score on the entire dataset\n",
        "res = {}\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    text = row['Text']\n",
        "    myid = row['Id']\n",
        "    # Check if the text is valid before processing\n",
        "    if isinstance(text, str):\n",
        "        res[myid] = pk.polarity_scores(text)\n",
        "    else:\n",
        "        print(f\"Warning: Skipping row {myid} due to invalid text.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvWjoAKVsxqq"
      },
      "outputs": [],
      "source": [
        "vaders = pd.DataFrame(res).T\n",
        "vaders = vaders.reset_index().rename(columns={'index': 'Id'})\n",
        "vaders = vaders.merge(df, how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjERsLAqw_U7"
      },
      "outputs": [],
      "source": [
        "vaders.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDYEnG6TxPtc"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNfbB56ExVM8"
      },
      "outputs": [],
      "source": [
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvPuR3g9xYdm"
      },
      "outputs": [],
      "source": [
        "pk.polarity_scores(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7b_--_axb77"
      },
      "outputs": [],
      "source": [
        "encoded_text = tokenizer(example, return_tensors='pt')\n",
        "output = model(**encoded_text)\n",
        "scores = output[0][0].detach().numpy()\n",
        "scores = softmax(scores)\n",
        "scores_dict = {\n",
        "    'roberta_neg' : scores[0],\n",
        "    'roberta_neu' : scores[1],\n",
        "    'roberta_pos' : scores[2]\n",
        "}\n",
        "scores_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebEA6PyJxjpC"
      },
      "outputs": [],
      "source": [
        "def polarity_scores_roberta(example):\n",
        "    encoded_text = tokenizer(example, return_tensors='pt')\n",
        "    output = model(**encoded_text)\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    scores_dict = {\n",
        "        'roberta_neg' : scores[0],\n",
        "        'roberta_neu' : scores[1],\n",
        "        'roberta_pos' : scores[2]\n",
        "    }\n",
        "    return scores_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAkr2gd8yrC4"
      },
      "outputs": [],
      "source": [
        "res = {}\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    try:\n",
        "        text = row['Text']\n",
        "        myid = row['Id']\n",
        "        vader_result = pk.polarity_scores(text)\n",
        "        vader_result_rename = {}\n",
        "        for key, value in vader_result.items():\n",
        "            vader_result_rename[f\"vader_{key}\"] = value\n",
        "        roberta_result = polarity_scores_roberta(text)\n",
        "        both = {**vader_result_rename, **roberta_result}\n",
        "        res[myid] = both\n",
        "    except RuntimeError:\n",
        "        print(f'Broke at id {myid}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-7WHxuPzNjm"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(res).T\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'Id'})\n",
        "results_df = results_df.merge(df, how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRVcvWGgzhe3"
      },
      "outputs": [],
      "source": [
        "results_df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "049aEMNuzhQn"
      },
      "outputs": [],
      "source": [
        "results_df.query('Score == 1') \\\n",
        "    .sort_values('roberta_pos', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUoDh6qnzhOs"
      },
      "outputs": [],
      "source": [
        "results_df.query('Score == 1') \\\n",
        "    .sort_values('vader_pos', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2ytk2U8zhMp"
      },
      "outputs": [],
      "source": [
        "results_df.query('Score == 5') \\\n",
        "    .sort_values('roberta_neg', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QclhH-eYzhK0"
      },
      "outputs": [],
      "source": [
        "results_df.query('Score == 5') \\\n",
        "    .sort_values('vader_neg', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "ScezR5NPT-3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "cEDU5jB3TmAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"Text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "dataset = Dataset.from_pandas(results_df[['Text', 'Score']])\n",
        "dataset = dataset.map(tokenize_function, batched=True)\n",
        "dataset = dataset.rename_column(\"Score\", \"labels\")\n",
        "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ],
      "metadata": {
        "id": "lVLTGaoCTpAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "# trainerr setup\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    eval_dataset=dataset,\n",
        ")\n"
      ],
      "metadata": {
        "id": "t76L4q-cTs7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(\"./fine_tuned_sentiment\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_sentiment\")"
      ],
      "metadata": {
        "id": "pkZP3YCeTv_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRduUSLZzhI0"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "sent_pipeline = pipeline(\"sentiment-analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lets_predict(s):\n",
        "    tokenizer_fine = AutoTokenizer.from_pretrained(\"./fine_tuned_sentiment\")\n",
        "    model_fine = AutoModelForSequenceClassification.from_pretrained(\"./fine_tuned_sentiment\")\n",
        "\n",
        "    inputs = tokenizer_fine(s, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    outputs = model_fine(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    label_mapping = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "    return label_mapping[predicted_class]\n",
        "\n",
        "s = input(\"Enter a sentence: \")\n",
        "print(lets_predict(s))"
      ],
      "metadata": {
        "id": "f4VOiVtSP5r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "DpkhGFCpP-KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(pk,open('pk.pkl','wb'))"
      ],
      "metadata": {
        "id": "LoJMGRVcXBOR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}